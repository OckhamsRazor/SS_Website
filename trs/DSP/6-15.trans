sil
ok 那再來呢這還有另外一招就是說
如果說詞這麼難弄的話
我們也有一個辦法
是根本就不要去管什麼是詞了
我們就把凡是經常會出現在一起的pattern 當成一個詞
嘛這個我們稱之為second pattern 
什麼是second pattern 呢就是幾個字經常出現在一起
不管它是不是詞我也不管詞的bound 詞的boundary 在哪裡我都不管
只要經常出現在一起的
我就當它是一個pattern 
我就把這個pattern 放在lexicon 裡面
我這個lexicon 不要想成是詞典
就是把這堆pattern 放在一起這些東西就叫做lexicon 
什麼叫做經常出現在一起的字把它兜在就把它放在lexicon 裡面呢
我們底下有一些例子你一看就了解了
就是經常出現一起的pattern 
我們直接從網路新聞裡面把它抽出來
那它其實不是在詞典裡面的詞的
就兩字的pattern 而言你看這種兩字你就知道
啊
有些是oov 像這個oov 啦
這個只是一個oov 而已
但是你因為在那那段時間它新聞出現很多的話
它其實是可以當你你可以抓得出來
那多數是兩個單字詞
但是呢這兩個單字詞談常常會連在一起
那你就乾脆的連在一起了啊
那三字的pattern 呢常常是一個兩字詞跟一個單字詞
它們經常連在一起就會變成一個三字的pattern 
當然oov 也是會這樣子可以抽得出來
那雙四字的話呢常常是兩個四字的pattern 常常是兩個雙字詞
譬如說兩個雙字詞
那它們這兩個雙字詞經常連在一起就乾脆變成一個四字詞算了嘛
sil
那這個觀念就是說我不不去管什麼是詞
我只是管我用我的database 去train 
說哪些經常黏在一起的就給它黏在一起
黏在一起的時候呢就變成一個所謂的segment pattern 
然後呢我就把這些pattern 存起來當成是lexicon 
那這個好處呢你馬上想得到就是我就不管這個詞的到底哪裡是詞
而我可以完全就是你只要給我夠多的database 
我就上網去抓我要的東西之後我就自己抽
那我就建一個我的詞典就對了
我根本不管那些那
怎麼抽這個pattern 這也有很多方法
不過我們用的最成最成功的簡單的方法就是我們之前講的那種
就是minimize perplexity 
就是剛才講的跟剛才講的這個很像啊
這個
跟這個reference 講得很像就用它的方法
那所不同的是我現在是要連起來的
我現在是要連起來的怎樣呢就是說
剛才那個是說你要你任意兩兩的詞你都要去算它們能不能連
我現在不用
我現在只是相連的才要看它們能不能連嘛
所以譬如說我的網路上抓到的文章是這樣子的話
你一開始
每一個字自己是一個pattern 
然後第二步開始哪兩個字可以連成一個pattern 呢
你去看這個能不能
這個能不能
對不對
這個能不能這個你你你這相鄰兩個去看它們能不能連起來
看這個能不能
那你怎麼看呢也是一樣
就是這個啊minimizing perplexity 
就是我現在如果它們連成一個詞的話
連成一個pattern 的話
我的perplexity 有沒有降低
降低多少
它們兩個連起來的話呢我的perplexity 有沒有有沒有降低降低多少
我就用這個來算
那當然你不必去考慮說
這
個跟這個會不會連
它們現在不在一起你就不用管了嘛
所以跟剛才那個不一樣的地方是在這裡
我現在是有一個語料在這裡所以我就我不必管它跟它能不能黏這種問題不用考慮
那你只要看它跟旁邊能不能黏
如果它跟它己經黏起來的話
那下一步是這個東西跟左邊能不能黏
對不對
如果這個已經黏起來的話呢那再來要考慮的是它左邊要不要黏
右邊能不能黏
就這樣子
那你用這個方法來你都每一次都算
我的perplexity 是有增加還是減少
增加多少
用這個方法你可以得到一個minimum perplexity 的一個新的lexicon 
那它不是我們平常所習慣的詞
但是裡面有很多很多我們的詞都自動抓得出來
那那譬如說專有名詞自動都會抓得出來
然後很多這種pattern 都自動可以抓出來你就得到一個新的詞典
