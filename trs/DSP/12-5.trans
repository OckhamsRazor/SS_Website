那這個東西可以拿來做很多用途
不僅僅是做 language model 
那麼我們可以看一下有些什麼用途
譬如說把詞分群
詞分群幹嘛
就是把相類似的代表相同意思詞 group 在一起
這個可以做很多用途
譬如說一個例子是做 language model 做 class space language model 
你記得我們之前講過的
我可以把相類似的詞變成一個 class 
然後拿那個來做 class 的 n gram 
而不要做每一個 word 的 n gram 
那這個詞分群這一個方法就是用這個
那同樣呢因為你知道你哪些詞在一起嘛
你現在每一個詞都是這八百維裡面的一個點了
那你可以在這邊做 v q 或者做什麼東西都可以了嗎對不對
你就可以把詞分群了嘛
那同樣你可以做 information retrieval 
就是說你在做搜尋的時候
譬如說你現在打進去 google 
我要找九一一恐怖攻擊
那它只會找文章裡面有九一一恐怖攻擊的事情
如果文章裡面沒有講九一一但是它講了賓拉登呢
會不會呢不見得會
可是在這裡我就會啊
因為我知道九一一跟賓拉登是在一起的它們很近嘛
所以呢因此我在做 information retrieval 
就是你在搜尋的時候我可以不完全根據字
而是你可以看它們的在這裡面的距離近不近
近的就是就是有關的嘛
那這邊就是剛才已經講過了
因為我的 word 在這裡
你只要看兩點接近就代表它們的意思是相關的
那一個可能的做法
這是一個例子不是這是 example 的 similarity 你怎麼量這個詞像不像
這個例子就是內積嘛
對不對你現在有兩個 vector 在這裡
你算它們像不像你就算內積嘛
那這個內積就是就是這個嘛
就是內積除以它們的長度
這就是 cosine theta 
就代表它們的相似度嘛對不對
這是一個例子你可以用這個
那就用這些 vector 代進來做
那這裡的每一個 vector 其實就是 u j 的 bar 
就是 u s 
這裡的每一個我每一個 vector 怎麼算就是畏用這個來算
就是由 underline 的這個 vector 
也就是 u 乘上 s 
u i 乘上 s 
所以你就是 u i 乘上 s 去算
就變成這樣子
那這就是詞的相似度
你可以詞可以做 clustering 
同樣呢我文章也可以做 clustering 
文章 clustering 是什麼呢
你可以想像有一個什麼用途譬如說 class language model 
我現在從我現在上網抓十萬篇文章
我可以用這十萬篇文章 train 一個 language model 
不過這個 train 出來 n gram 是很亂的
因為裡面什麼東西都有
它從從這個李安的電影到賓拉登到什麼全部都在一起
混在一起變成一個大的 language model 之後
中間的各種 n gram relation 是被攪混的
那因此呢我可以把它分群嘛
我如果上網找了一百萬篇文章之後把它分成一百群
每一群是比較接近的文章
再把那一群去 train language model 
那就會比較好嘛對不對
那這就是所謂的 class 的 language model 的意思
我可以把找到的一百萬篇文章先分成一百群
分別去做 language model 
同樣我也因此可以做 language model 的 adaptation 喔
