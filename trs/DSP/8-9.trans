那這樣子的選法呢
這個這在a i 的課本裡面他們他們有一套說法
那麼這個說法就是嗯第一個它有一個叫做所謂的admissibility
所謂的admissibility 是說有某一種search 的方法是admissible
如果保証你找的第一個solution 就是optimum
只要optimum solution 存在
只要optimum solution 存在你照那個algorithm 去做
你找到的那一個第一個就是optimum
這個叫做admissible
那當然很多時候你的你的algorithm 不是 admissible
那當然我們會希望
它是admissible
那麼舉例來講
我們剛剛講的beam search 顯然就不是因為
beam search 我已經很可能把那些個嗯optimum 都已經丟掉了
所以beam search 顯然就不是
它只是一個practically engineering solution
它適合engineering 的方法來得到答案而已
它不見得是
喔它顯然不是
那
嗯
我們比較希望我們的方法是admissible
那麼也就是說只要存在一個optimum solution 我就照這個方法去找的我的第一個solution 就是
有沒有條件呢有的
這個這個這是這個一個定理
在課本裡面有
那a i 課本裡面也有這個到處都有
那我們這邊並沒有打算要去說它如果你有要了解它的 exactly 的意思
或者它怎麼証明的
課本都查的到
不過講起來很簡單就是說
以我們剛才那個case 而言你如果是要最高分數的話
你可以証明它是admissible
你的條件就是我的所有的都是高估
那h n 是什麼
h n 是真正的
我真正的從這裡到那裡
真正從這裡到那裡會得幾分是真正的
那h n 的star 呢是你的估計值
那麼
這個
定理是說呢你如果是一個最高分的problem 你要找最高分我們剛才像剛才這個就是我要找最高分看走到哪裡最高分
你如果是要找最高分的話
你其實就是
你所有的都是高估
你只要所有的都是高估
你就會得到
那麼就就它就是admissible
反過來如果是minimum 的problem 的話
像我們前面那個
是一個 minimum distance 的problem
你要minimum
的話呢那反過來就是要低估
你如果所有的都是低估的話
它就是admissible
那
這個
詳細的証明我們就不講
那凡是符合這個條件的admissible 的話呢我們就說它叫做a star search
喔這個a star 這個是a i 裡面的名詞
那
那麼因此我們會prefer
這種a star
那麼它的基本的做法
那那這樣來的我們這個這樣一來這個heuristic
這些heuristic search 就有道理啦
喔
我們剛才講好像沒什麼道理因為你你憑什麼估記
你憑什麼去估這個東西呢
那現在有一個很簡單的原則就是你要高估或者低估
你如果要minimum distance 就是要每一次都低估
然後你如果有 maximum score 就是你每一次都要高估
你如果就是高估或低估的話就可以保証你是
a star
嗯這叫做所謂的a star search
那這個做法就是我們剛剛已經講過就是每一次
凡是你有得選的時候
你就把所有的可以選的都算一次
算的時候就是包括剛才講的這兩個嘛
就是
已經知道走到這邊會有幾
的分數以及我高估或者低估的那個分數
把它加起來
然後你把它列出來看看誰誰是你要的
你就照那個來選
你如果是這樣子的話
所以呢譬如說這邊講你如果是要最高分數的 problem 的
話
你就是用高估的
然後呢你每一次可以選的時候就選那個最高的
那這樣的話呢你這個就是一個a star
然後你就是可以得到admissible 的的答案
好
那我們大致這樣講那做語音的時候怎麼做
做語音的時候是一樣的情形
你可以想像的情形是說
其實我們是在做一個跟剛才一樣的
這個multi multi pass 的search
但是呢我在第二個pass 的時候我現在可以用a star
因為我在我在第一個pass 走過來的時候譬如說
我已經建好這個tree 了
tree 上已經有很多東西了
我可以用這個tree 上的知識
來來估計
來高估
所以我第二次重走的時候呢
我就可以走a star
我就可以算說
我走這個的話後面估計是多少
如果我走這個的話後面估計是多少
我走這個的話後面估計是多少等等
那就等於說我是在這個
所以呢我的這個第二步的時候呢我可以用 a star 的方式來做
來make sure 我走的是admissible 的
然後我會得到optimum
至少在在那個word graph 裡面是optimum
喔
等等
雖然我一開始建的時候可能我有把最好的丟掉是有可能的
那這個是這我們用a star 來做那一塊基本上是這樣子
那你怎麼用
這個這個tree 這個word graph 上面的東西來估計
做這a這a star 要估計啊
要做高估啊
那
你怎麼怎麼個高估法呢
那我們這邊舉兩個例子很多方法都可以用
那我們舉這兩個兩個例子
那第一個例子呢就是說
你你估計時間
你先估計這個 average score per frame
那舉例來講呢我可以有training data
那麼我可以算這個東西
這是什麼呢
這是o i j 就是我一堆observation
從frame i 到frame j
然後呢
q i j 是它的一個state sequence
然後中間呢有多長
因此呢這個就是
我如果有一段signal
這是從time frame i 到time frame j
那麼這一段呢
它假設走某一個state sequence
走過來
那麼這個呢就是o i j
這個呢就是q i j
那我如果是
假設是given 這一個state sequence 的話呢
它的總分數是多少
那麼總分數是多少呢我除以j 減i 加一就總共多少 frame 嘛
那我大概可以估計這個每一個frame 每一個frame 分數是多少
那這樣的話呢我現在如果有夠多的training data
我可以用這個來統計
我大概可以算出來平均每一個frame
每一個frame 它的分數
平均是多少maximum 是多少minimum 是多少等等
這些都知道了
然後呢
因為我剛才在b第一個pass 已經走過一次
所以我就知道
每一點到最後的時間還有多少
我就用這個時間來算
這就是t 減t
大t 就是
最後的
那你在時間t 的時候
那你可以估計我這邊還剩下多少個frame
對不對因為我前面已經走過一次我的first pass 已經走過一次
我已經知道到到大t 會結束 大t 是多少我已經知道了
因此我現在到這個node 的話呢我其實我已經知道
還剩下多少時間
然後我可以估計平均每一個frame
會有多少時間minimum 是多少時間maximum 多少時間等等
我可以用這個來來算
我每一點估計到最後大概有多少時間
那這樣的話我就可以得到我的這個heuristic 分數
用那個來估
那我現在是要高估
那我就我要make sure 我找的是maximum 我就高估好
等等
那第二個例子是差不多的情形就是你先在現用week constraint
可以得到它的分數
那那個可以拿來當做heuristics 用
就是說你現在我剛才假設我只用
我沒有用tri phone 我只用最簡單的phone model
我也可以得到它們的acoustics 分數
我沒有用tri gram 我只用bi gram 我也可以得到它們的
linguistic language model 分數
這些分數都可以拿來做estimate嘛
所以我可以用第一個pass 所得到的比較粗的
東西
所以呢這個這個first path 得到的那些比較粗的week constraint 的分數
拿來估計我的heuristic
也可以啊
那其實這個估計的會比剛才那個還更準一點啦
喔因為我這個可以把那些分數算進去
那這樣的話呢我這個都是這類的分法
那這樣的話我們的這個之前講的這個這個multi pass 的方法呢
其實我到第二個階段的時候我就可以做a star
那這個也是一個常用的方法
好那到這裡呢我們八點零講完了
那麼嗯或者說是我們的這個所有的basic 到這裡都講完了
那我們來先來說一下期中考
今天是四月今天是四月二十五
下週是五月二號
五月九號五月十六號
期中考範圍到這為止
所以呢這個我上次提過合理的考試時間可能是兩週以後
但是呢我希望排在十六號
原因是那週我出國
那所以那週考試的話我們不影響進度
就可以大概可以至少可以等於是補了一次課一樣啦
那所以我們十六號考試沒問題吧
好 ok 那所以我們期中考是嗯五月十六號
我們的考試時間兩小時
也就是十點
我們十點十分到十二點十分好了好不好
我們就是考最後的考後面的一百二十分鐘
這是所以就是十六號那一週我出國我們就是考期中考
十點十分到十二點十分
考試範圍是到八點零為止
那麼我會在下週把上一次的考古題發給各位
那你就比較容易知道我會怎麼考
那嗯這個期中考不會難
因為並沒有要為難各位喔
那麼期中考的目的其實最簡單的就是兩件事
第一個就是make sure 大家有在念書喔
那我了解這個我們台大同學的這個最主要的問題就是如果不考試的話你就不會念的嘛
所以呢我們就是需要考試來make sure 你有念書就是了
然後當然第二個目的是我們得要有個分數喔
要有分數才能夠才能夠算成績嘛喔
喔只是這樣原因而已
所以期中考不會難考
喔但是你要念喔
要念什麼
除了你不是光是上課講這些東西而已
我每一個每一個八點零七點每一個點零的地方前面都會有它的reference
這些基本上我大概都會說到
喔譬如說我剛才講這個時候我就會說這三個裡面你選一個嘛
有or 就是你選一個
要念其中一個
嗯然後呢那這個我就沒有說你一定要念啊我就說這個是一個很好的reference
那這個我也沒有說你要念啊喔
這我就說這個是屬於那個古代的方法裡面的很好的reference
所以這兩個應該是不會考的譬如說
我都會再講到
所以呢那但是呢我如果有講說什麼地方要念你要念哦不然那個地方會考到
那然後我們這門課因為修課同學background 差異很大
我們從大三一直到博士班
從資工的到電子的到什麼都有
所以呢我們基本上哦你可以假設就是這我之前也講過就是
你如果會覺得沒有辦法看下去你就跳過去
你繼續往下看
但是當你看了很多之後你可以回過去再看
你可能發現你原來你看不下去的地方你再看就看懂了因為你看了後面的東西
喔所以你always 可以再跳回去看前面的
如果你跳回去看仍然看不懂的話
那那個地方不會考啦喔
那基本上就是這樣喔
所以我想我會考的部分應該是不會depends on 你的某個專業的background 的
所以呢我想這個是這個期中考的部份
然後呢我們的習題還有第二題會在下週給你
但是交習題時間會在期中考以後哦
所以第二題習題是做language model
就是train n gram
哦等等
因為你的第一題是acoustic model 嘛哦
第二題是language model train n gram 嘛
會在下週給你
然後在考後交
那之後的話你現在就等到期中考考完之後
你只要把第二題習題交完你只剩下一件事
就是期末報告
喔那所以呢
那這個我們從下週以後開始我們就在講後面的了
我們這個fundamental 到這裡結束
那那我下週開始我用跳的
所以呢喔我下週會先直接講這個這個十一點零跟十二點零
然後會往下走
那麼我九點零跟十點零
屬於另外一些個理論比較多的東西
我覺得留到比較晚一點再說
那從十從這個十一點零以後都是各個研究領域的相關的適合給你做報告的題材
喔所以呢我儘可能提早先講這些個各個研究領域的部分
那麼讓你提早接觸這些東西
這樣你期中考一考完你就可以開始思考你期這個期末報告可以做什麼
那在這個裡這裡以後我講的方法就會跟這邊都不一樣了
因為到這裡八點零為止我們是在講basic 所以我每樣東西講得很慢
那從十一點零開始
那其實我每一個都只講它是什麼然後觀念是什麼
我就跳下去了
哦就不斷用跳的
所以從這後面開始會用比較快的跳的方式來進行
那麼跟這邊的我們講的basic 是不太一樣的喔
好這個是講這個我們之後的進行的情形
那麼所以呢底下我們可以稍微開始一點點十一點零
那麼十一點零我們在講的是speaker
從這裡開始我剛才講我們現在就講一樣一樣東西
我們每一樣東西就會給你reference
然後這個嗯我每一樣都只講一下它的基本精神就往下跳了喔
那我們十一點零是講不同的speaker 聲音不一樣的問題
那你可以想像我們到目前為止沒有考慮不同speaker 會怎樣
但其實每一個speaker 聲音是不一樣的
我們說ok
這堆是嗚
這堆是啊
這是一個很粗的說法
如果單獨一個speaker 的話
一個人它的嗚是會這樣子
有一個distribution 啊會有一個distribution
但是你如果一群人的話它的嗚顯然會比較大
那它的啊也顯然會比較大
於是就會overlap喔
那因此呢你你這個不同的人顯然就會有很多不同的問題跑出來喔
那麼那麼我們要解決這個不同的speaker 的問題
那我們底下會說一些重要的方法
那我每每一樣重要的東西我們就會列個reference 給你喔
那這些都是我們後面你如果要做期末報告的很好的起點
那我們先說一下這裡的主要的problem 是什麼
那麼基本上來講最好的當然是speaker dependent
也就是說我只為一個speaker 來train
只用你的聲音train 你的系統
這個顯然是正確率最高的
只是說呢我們需要大量的data
那你的聲音需要train 所有的tri phone
對不對需要train 所有東西
所以呢你這個這個本身就已經很大了嘛
那麼在早年做語音研究的時候人家都以為這樣是最好的方法這樣正確率最高
不過到後來就知道這個是不可行
為什麼不可行
就是因為需要的training data 太大了
而天下的user 是天下最懶惰的一群人
如果你要叫他先發夠多的聲音去train 的話就沒有人要發
所以呢天下最懶惰的一群人就是user
所以就不要靠user 的話是不可能的
所以最後我們就知道這個solution 是不通的
那後來就有人想說那這樣子嘛我們做multi speaker
譬如說同一個家庭的人聲音都比較像
這個兄弟姐妹都很像
所以呢你就可以把他們train 成一個model
那是不錯啦喔
你這樣的話是因此呢你如果本來要用十個小時的data
你兄弟姐妹四個人所以呢
你每個人用二點五小時嘛哦
那這個是稍微有點好處但是幫助不大
這個沒有太多用
所以這個後來也放棄
那最理想是什麼 speaker independent 嘛
那就是我用譬如說找一千個人
來五百個男生五百個女生
那我這樣的話我就可以train 所有的聲音都在裡面了
那這樣子的話呢就這個這個每一個人其實這一千個每一個人可能只要三十分鐘的data
我就可以那這樣我希望可以good for all speakers
但是這個turns out 也不那麼成功就是因為
我的accuracy 一定會比較低
就是我們剛才講這個情形嘛
你如果一個人的時候我可能啊跟嗚可以分得開來
可是當你可能有一千個人的時候呢每一個人的嗚不太一樣
所以它的distribution 就會變大
每一個人啊都不一樣就會變大所以顯然就會overlap
於是就不容易分得開來嘛喔
所以呢這個時候呢speaker independent
顯然是我們都希望的
但是它的缺點就是accuracy 一定會低一點
那麼今天其實我們所有的語音系統
幾乎都是這個
但是呢它都是會差一點喔
就是我們幾乎已經沒有沒有這個speaker dependent 的case
或者這個幾乎是沒有了
但是呢大概都是朝這個在做
但是都不會太好
那怎麼辦
那最好的solution 我們今天所知道的最好是這個
就是speaker adaptation
就是用這個speaker independent 開始
但是呢它去學speaker 的聲音
你儘量學
讓你說最少的話我就學會你
所以譬如說呢你一開始是一個speaker independent model
所以我一開始的時候我我輸入的時候它的正確率稍微低一點
這個也有也有技術你怎麼樣做得比較好
但是不會特別好
那這個時候呢
當你開始對它講三句話講五句話之後
它就馬上學進去
它就開始知道你的聲音是怎樣的
它就會開始知道說喔你的嗚其實是這一群
你的啊其實是這一群
如果它有辦法幫你把根據你講的那少數的幾句話
就幫你把你的嗚由這堆收縮到這兒來
啊由這堆收縮到這兒來的話呢
欸你就分開來了嘛
所以呢你就可以這個用這個limit quantity 的data 用少量的data
我們稱之為adaptation 的data
於是呢你就可以學你的聲音
於是你就可以正確率可以馬上提高
那這個觀念是技術上是可以做得到
實際上也是可行
也就是說我們今天所看到所有的系統幾乎是這一種
也就是基本上它是speaker independent
但是你如果跟它講話講的講的話他就越學越快喔
那就是所謂的speaker adaptation
那我們這個十一點零主要就是講這個speaker adaptation
那怎麼樣來讓系統讓這些model 學你的聲音學得最快
那這裡面可我們可以分成supervised 跟unsupervised 兩種
那所謂的這個 supervised 是說你所輸入的東西假設是知道的
譬如說這個一開始系統先先跟你講幾句話
先叫你說個什麼
那其實你就照它說
所以你說的話是它已經知道的
因此呢它完全知道你的這些你輸入的這個聲音裡面
這是什麼phone 這是什麼它完全知道
因此它就可以用這個phone 去train 這個
用這個phone 去 train 這個等等
它都知道那這是所謂supervised
但是這個比較不太好的地方就是在於你user 一開始得要回答系統一堆問題
喔user 可能不喜歡
那user 喜歡可能我就開始我就跟他講我要講的嘛
如果是那樣的話呢
就表示user 一開始說的我系統已經不知道他在講什麼了
所以呢怎麼辦呢
也就是我的 text 你輸入的聲音的文字它其實不知道
那這個時候呢
你知道一開始就是用用speaker independent model 去做辨識
所以我一開始不知道這你在說什麼但是我就用我這個model 去辨識
它可能是這個它可能是這個
那我就用它去train 它跟它去train 它
那這樣當然會有錯
有錯所以呢可能是你要你如果可以iteratively
perform 會比較好
也就是說
我現在你講的第一句話我雖然不知道是什麼但是我就用我的原來的speaker independent model 去辨識一下
說這個可能是這個
這個可能是這個
所以我用它來調它用它來調它
當我把這些都調過之後這個比較好了
我再來辨識一次
我可能會辨識比較準嘛
等等我可以用 iterative 方式
來做那這是所謂unsupervised
那我們今天比較prefer 是這一種
這樣你系統 user 可以跟系統直接講話
然後呢你就可以進步
但是這個就是說這個有技術嘛
那再來呢我們可以分成batch 跟 incremental online 的區別
所謂batch 就是你輸入一堆然後它一起幫你幫你調
incremental 就是你一步一步跟它講它一路調
也就是說舉例來講譬如說你你當你講了前三句話的時候
它就根據你的前三句話調一次
你又講了三句話的話呢它會再調一次
或者根據你的前六句話重調一次
就你不斷的講它不斷的學喔
這樣子它的正確率不斷的提高
這是我們今天大部分是這種
就是incremental 的或者是online 的
那當然 batch 的話是會其實會效果更好
你給它一堆
它一次喔
因為你一步一步的時候可能都 step by step 的時候很可能每一步都不是optimum
因為你再加東西之後呢你的前面那個就已經不是optimum
喔所以呢但是反過來呢我們在user 來講是這個比較比較attractive的喔
所以大概這是adaptive adaptation 的這些東西
那我們底下就會講adaptation 幾個重要的基本的方法跟觀念
然後我就會給你這些reference 等等喔
那我會告訴你哪個方法的reference 哪一個等等等等
那這是後面的從下週以後我們的上課的方式會變成這樣
那不像我前面會把它講得那麼清楚
好那我們今天上到這裡
