這個假設零到九十個音可以這樣子做那我現在如果是一個連續的聲音裡面有任何可能的音的話怎麼辦
那複雜很多那就是我們所講的這個大字彙連續語音
他進來一段聲音很進來一段聲音然後呢我每一個字每一個詞都可能是有六萬種可能
那這個怎麼辦那我們通常是用這個辦法這張圖是用英文為例所以我們講的是英文英文也是差不多的
英文常用詞可能也是六萬所以你也是假設第一個字可能是六萬個
這個第一個字有六萬種可能這個也是六萬種可能所以你這個字是非常不容易處理的那這個時候要怎麼辦呢我們通常的辦法是這樣假設要處理英文
假設我輸入這句話是 this  is  speech
那這時候怎麼辦呢我事實上是先把英文的所有的基本的單位音分析出來
比如說在英文的基本單位音裡面這是一個基本單位音這是一個基本單位音等等等等等等
因此呢我總共的基本單位音沒那麼多
這個可能是數十個或者是數百個就這麼多而已
那麼因此呢我的每一個基本的單位音看成是剛才上一頁的那些零跟一的 pattern
那我把這些基本單位音都建成了 pattern 之後那麼我現在進來一串聲音我就去跟那些剛才的 pattern 來比對
那麼那些呢我把他呃稱之為 acoustic  model
所以呢所謂的 acoustic  model 其實就是現在只有這一隻這一隻好像沒電了耶我所所謂的 acoustic  model 其實就是這一堆基本的單位音他們的這一堆基本的單位音他們的這個 pattern
那麼因此呢我就可以跟它比對
那這些基本單位音的 pattern 怎麼來的當然還是要用這個聲音去訓練出來的經過訓練程序訓練出他們的 model 來
那麼這個 corpora 這個字是我們常用的其實就是我們翻成中文就叫語料就是語言的或是語音的 data  base
我用一個 data  base 裡面有各種各樣的聲音的 data  base 我訓練出這些基本單位音的 pattern
於是呢我的第一件事你可以想像的是我的聲音進來經過一些這 front  end 的 processing 得到 feature  vector 就是我這邊所畫的東西
那麼我等於是在喔把這些轉成這些 vector 那就是這一塊的所謂的 front  end  signal  processing 在做的事
然後得到我這個一串的 feature  vector 之後呢
我現在第一步就是跟這些基本單位的 pattern 來比對
假設我得到說他是這一堆單位音
再來呢我有一個辭典這個辭典告訴我說這三個音拼起來是這個字這兩個音拼起來是這個字這幾個音拼起來是這個字
那這樣呢我就可以猜說他可能是 this  is  speech
這樣想起來好像容易其實這樣講實在是太簡化了問題
為什麼呢因為事實上你可以想像這個音跟這個音是很像的跟這個音也是很像
那麼因此呢我辨識的時候我不太容易判斷第一個音真的是這個音我很可能會覺得說第一個音很可能是這個音也很可能是這個音也很可能是這個音
第一個音至少有這三種可能那第二個音呢可能是這個音也可能是另外一個音也可能是另外一個音所以他也有三種可能
第三個音呢雖然是好像是這個音但是他也很可能是這個音他也有點像是這個音等等
所以你可以想像其實我不是那麼單純說哦前面是這三個音所以就是這個字不是這樣子而是我很可能這有很多可能音這有很多可能音這有很多可能音那他們兜起來可以兜成很多不同字
所以到底是哪個字我不知道啦因此怎麼辦咧我後面要用一個所謂的 language  model 那就是這個
那 language  model 是什麼呢他告訴我說哪些個字連起來是比較像一個句子
那麼他這樣連可能是一個字這樣連可能是另外一個字這樣連可能是另外一個字那麼因此呢我到底什麼字接什麼字可以有很多很多種我在這裡面找出一個連串的 sequence 來而他的機率最高最像一句話
譬如說在句首我先看這個字在句首的機率如果前面有這個字的話後面會接這個字的機率前面有這兩個字後面再接這個字的機率等等
那這樣乘起來就變成是這些個字連起來是一句話的機率我們用這個方式來算然後找一個字串是這個機率最高的
那麼這個的過程怎麼做呢那個其實我們這個東西是用另外一個 text  corpora 這也是一個 corpus 不過這個是文字的這個是聲音的
那這是文字的 data  base 譬如說上網去抓一千萬個網頁下來那裡面就有十億個字的文章於是你就可以用這個去計算譬如說這個字在句首的機率是多少然後前面是這個字的時候後面會接這個字的機率是多少都可以算的出來
那因此我就得到這些東西那這些個機率存起來就是一個我們稱之為 language  model 語言模型
就存在這裡那麼因此呢我現在就根據這個語言模形去算所有可能存在的字串裡面誰的機率最高那那個就是我的答案
那這裡面呢這種 language  model 我們通常有很多種我們後面會詳細說這邊簡單的舉例譬如說呢我們叫做如果是前面是這個字後面接這個字的機率是多少這個叫做 bigram 前面兩個字後面接這個的機率是多少叫做 trigram 就是兩兩相連跟三三相連的機率
就好像這個呢是 bigram 的 probability 這就是 trigram 的 probability 等等那這就是我們的 language  model 那他是用一個文字的大的 data  base 所 train 出來的
那麼這是一個簡單解釋說明呢這個大概是這麼做的不過這個要詳細做的好呢這裡面有非常多的學問所以我們其實前面的半個學期都在講這個 exactly 怎麼做
我們在這個一點零我們在二點零其實還會再詳細再稍微詳細一點的說的他們大概是什麼
然後到了這個三點零也是那麼到了四點零開始四點零五點零我們詳細說這個 acoustic  model 怎麼做
就是這些個基本單位音的 pattern 怎麼做六點零我們講 language  model 怎麼做七點零我們講這個 front  end 怎麼做八點零我們講這塊怎麼做所以我們到八點零才會全部講完這張圖
