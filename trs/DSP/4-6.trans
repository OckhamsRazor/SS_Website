底下我們要進入比較難的就是這三個 basic  problem 
那這個我們其實上週已經說過一次
我們真正要解要用 H  M  M 來做我們要做的事情的時候
最核心的三大問題就是這三大問題
那麼我們底下要做的事情就是講這三個問題的 solution 
那我們今天會講 problem  one 跟 two 
大概今天的時間是講這兩個
然後呢 problem 三留到下週
我們從這個 problem  one 開始講起
喔不在這兒了我要跳到另外一個去
 ok 在這裡
那麼這是我們來看 problem  one 來解這個問題
那麼 problem  one 其實是這裡面最容易解的一個
這個因為當初這個不在一不在同一個時間做的所以這個不是 powerpoint 
那麼喔 problem  one 是這裡面最容易解的一個問題
那麼它的問題就是算我們剛才講的那個機率
這就是我們剛才講的那個機率啊
 given 一個 model 我會看到一個 observation 的機率
我就是要算這個
那這所以 given 一個 model 呢就是 given 某一個 n 個 state 的 model 
它有 n 個 state 有 a 有 b 有 Pi 都已經在那裡了
所謂的 Lambda 就是 a  b  Pi 各是一堆參數它們的集合叫做 Lambda 
 given 這個 model 然後呢我 given 某一個 o 
 o 是什麼就是 o  one  o  two 到 o 的大 T 
這個這段聲音總共的長度是大 T 
有大 T 個 observation  vector 
那麼構成一個大 O 我 given 了這個
那麼我想知道它們這個會看到它的機率到底是多少
那麼痾我們講這樣這個 problem 本身的這個問題其實就是在做 recognition 
我們舉例來講如果我要辨識零到九的十個聲音
我就是有十個這樣子的 model 
今天進來一個聲音是八
我就把這個八放進來在每一個 model 去算一個機率
那照說會在八的 model 的時候機率會最大
因為我放在我把八放在一的 model 放在二的 model 裡面它進去會很小
等等我所以這就是我們基基本上在做 recognition 的時候要算的機率
那我們要來看怎麼算
那麼要看這個之前呢當然我們要為每一個 o 呢 define 一個它是在哪個 state 裡面
就是 q  one  q  two 就是指它的
如果 q  one 是一就是它的第一個 state 等等
就是有它的 state  sequence 
好那就是我們這邊要講的問題就是這個問題
我這邊的所有的符號所有的 notation 都是 follow 那本課本裡面的第六章
那原因是說這樣子的話你去看那本課本的時候比較容易對
所以呢我這邊的 notation 都是照那邊的課本的
也因此跟我的其他地方也許稍微有點不一樣不過大致是很接近的就是
那麼這個 problem 怎麼求呢
基本上就可以用剛才的那個方法
這邊講的這個式子就是我們剛才的那個方法
那這個的意思其實講起來很簡單
就是說我現在要算這個 probability 就是
我要算這個 probability 的 o  given 這個 Lambda 
根據我們剛才的講法我就是要算什麼東西呢
每一個 state 每一個 state  sequence 
不過它這邊的 state  sequence 叫做 q  bar 
我每一個 state  sequence 叫做 q  bar 
就是我上面這裡嘛就是這個這個 q  bar 嘛就是我的 state  sequence 
 given 每一個 q  bar 然後呢 Lambda 
然後我 summation  over 所有的 q  bar 
你可以先把它寫成這樣子
這跟剛才那個是完全相同的
我就是我現在不知道哪個 state  sequence 我就假設某一個 state  sequence 那這有一個機率
然後把所有可能的 state  sequence 全部加起來這就是我的答案
那然後這東西怎麼辦呢這東西把它拆成兩個
那就是第一個呢是
如果是 given 某一個 state  sequence 的話
然後呢第二個是
那一個 state  sequence 的機率還是一樣
所有的 q  bar 
我就是把這個機率呢把它拆成兩個
跟我們剛才那個簡單的例子是完全相同只是我現在比較複雜而已
因此呢我如果是在某一個 state  sequence 看到這個的機率的話
我可以拆成我先 given 這個 model 會有那個 state  sequence 的機率乘上 given 那個 state  sequence 看到它的機率這兩個相乘
當我看拆成這兩個之後呢那就是我們這邊所寫的再下一步
那其中的這裡的第一式再拆出來就是上面的這一個
所以你看到我上面的這一個呢就是上面這個嘛
上面這一大堆東西這一大堆東西就是上面這個
上面這個就是這裡的第一式
然後乘上底下這一這一大堆東西呢
底下這一大堆東西就是就是它的第二個就下面這個
這個就是這邊的第二式
所以呢我這個就會這個這個再出來就會變成那一大堆
然後那個再出來就會變成這一大堆
那就是我這邊的式子
那這一這兩大堆其實也都很容易看
那麼譬如說如果它是這個 state  sequence 如果它是這個 state  sequence  given 是這個 state  sequence 的話
我看到這個機率是什麼呢那就是
把 o  one 放在第一個 state 去把 o  two 放在第二個 state 等等全部乘起來
對不對那就跟剛才我們那個簡單的例子是一樣的對不對
如果說我已經知道了是這個 state  sequence 的話
它的第一個 state 是 q  one 第二個 state 是 q  two 就是這個嘛
第一個 state 是 q  one 第二個 state 是 q  two 嘛
那我就把 o  one 放在第一個 state 的那個 B 裡面去
把 o  two 放在第二個 state 的那個 B 裡面去等等
這樣乘起來不就是這個嗎
就是這個
那至於說第二個呢
你如果要看到這個 state  sequence 機率是什麼呢
那你就從 initial  probability 開始啊
我的第一個 state 會是 q  one 的機率就是 Pi 的 q  one 
然後就開始用跳的嘛
從 q  one 跳到 q  two 的是 A 這是 a  i  j 
 q  two 跳到 q 三
一路 q 一路 q 這樣跳過來跳到最後一個 q  t 
那因此我就得到以下那個機率
所以這兩個就這樣可以算的出來
那這個式子其實跟我們剛才的那個
這個跟我們剛才那個簡單的那個 case 是完全相同的
你如果再看一次的話
我們來看剛才的那個就是在
這裡面的這個
 yeah 就是這張
我們剛才講這一張其實是完全一樣的
那麼在這個簡單的例子裡面很容易看嘛
就是這樣子
然後這個拆成這個這個拆成這兩個
就是我們剛才講的就是這個拆成這個這個拆成這兩個
那這兩個就是這兩個嘛
就是兩個就是就是這邊這兩個
然後這裡面的第一個怎麼算就是用這些東西來算
那麼第一個怎麼算用這些東西來算就是我們剛才看到的這一堆東西
然後呢第二個怎麼算第二個用這些東西來算
那就是我們剛才看到的這一堆東西
所以呢我們看到的這一堆只是這個簡單的問題的一個比較複雜的寫法而已
好如果這個沒問題的話那我們回過頭來看
它的問題在哪裡問題在這個計算量太大了
因為我我這邊要對每一個 state  sequence 都去算這些東西
然後我的 state  sequence 呢有多少個
有 n 的 t 次方個 in  general 
其實會比這個少一點啦不過也夠大了
這個 in  general 的意思是說我現在等於是假設所有 state 都可以跳來跳去
我假設是我有 t 個 observation 
我有 t 個 observation 
第一個呢假設是有 n 個 state 都有可能
第二個也是 n 個 state 都有可能
第三個也是 n 個 state 都有可能
所以有我總共有多少呢有 n 的 t 次方個
但是我這個 t 可能很大喔
譬如說我一段聲音你記得我們這些是 o  o 是怎麼來的
它是它是它是這個我這個訊號我這樣子取取第一個 o 嘛
然後這 shift 過來我再取第二個 o 嘛對不對
因此我這樣一弄的話呢我可以這個
平常你一個 utterance 你講一句話
我這出來是幾百幾千個幾百幾千個的這個 o 
那如果你這個 n 在幾百幾千次方就很大很大了
這個是這是 order 非常高的一個計算量
雖然我可以用 computer 來算
這個還是會非常非常大
那麼即使說 ok 我們簡化到讓它一定從這裡開始
所以譬如說我開始不會從中間開始不會從後面開始一定會從這邊開始
然後呢我規定它不能跳回去
使得我的這個 state 狀況少一點
但是也這個數目還是非常大
所以呢這個計算量是非常大的
所以事實上呢這個我們這個問題我們不是用這個方式來解的