那麼因此呢
我們整個的整個的這個recognition 的方法是word based 
在因為是在西方的語言英文為基礎的西方語言所發展出來的技術就我們剛才看的那張圖
一點零的那張圖
那張圖是以可以說是是word based approach 
因為你的lexicon 就是用詞來做的
然後你的language model 就是n gram 
什麼是n gram 
是詞來做的n gram 
所以你都是以詞為基礎來做的但是你現在如果詞搞不清楚的話
你整個都比較會有問題
這是中文裡面最常碰到的一個狀況
那麼這個時候呢
嗯
那還有一個問題就是你要會斷詞
你並不是隨便上網拿一大堆database 下來我就可以train language model 了
那你那樣能夠train 的就是字的language model 
字的n gram 你還可以train 
詞的n gram 你還不能train 你得要先會斷詞
那你的斷詞就是你要有一個程式去做斷詞的程式
那斷詞程式怎麼做
其實是不難
但是要做到好也是不容易的
你可以猜這個斷詞程式怎麼做
就是我有我有一個詞典
然後根據詞典做matching 
這是最基本的原則
我有一個詞典告訴我這些詞兩字詞三字詞單字詞
我然後來做matching 
我看到第一個詞的時候呢先去看所有的單字詞裡面有沒有它
如果它是一個單字詞的話那它可以是一個單字詞
可是呢我走到第二個詞去看的時候呢它是不是一個雙字詞
唉如果它有雙字詞的話呢長詞優先
如果這兩個是一個雙字詞的話呢我先考慮這可能是一個雙字詞
那就不要考慮它是單字詞了
那我再找到三字詞發現唉發現唉這個也是一個三字詞那三字詞又優先了
那我就考慮這個
這還有沒有四字詞沒有了
我從這裡再開始重新再來斷
發現了唉這邊這有一個雙字詞
再發現這邊有等等啊
你這第一個原則就是去做matching 
然後長詞優先
然後你可以從從左邊切左邊match 過來
你可以從右邊match 過來
你可以兩邊來走
然後另外一個就是你可以用詞的n gram 
sil
那到底是
你有的時候這樣子斷也可以這樣子斷也可以
那誰比較對
用n gram 來算
等等等等
這類的方法都可以做
這是所謂的這個斷詞的問題
那當然有的時候有ambiguity 當然有ambiguity 
譬如說不知道理由
是知道跟理由各是一個詞呢
還是道理這個不知道理跟由
那憑什麼n gram 是一種solution 告訴我說知道理由
而不是道理跟由
啊等等
那那這這些就是那那這個就是所謂斷詞的問題那你第一個呢你要有一個自動斷詞的程式
這樣子我上網去抓一大堆training data 來之後
我斷了詞才能夠train 我的language model 如果是以詞來做的話
等等
那這是中文的一堆問題
在這個問題之下我們就可以講了
就是說那我可以用字來train n gram 
我也可以用詞來train n gram 
到底那個比較好
它們之間的關係是什麼
這邊是講用字所train 的n gram 
這個上面是講用詞所train 的n gram 
那基本上來講呢
這個
用字來train 的最大的好處就是你就避免了一個斷詞的問題了
詞的結構你也不管了啦
就是用把字去數字就好了嘛所以呢它這個這是最大的好處你沒有斷詞的問題
也沒有oov 的問題沒有oov 的問題
你反正就去把每一個字都都當成是一個單字
它就自動都有所有的
這都是一個一個word 就對了
你這樣就去算就是了
這是最大的好處
但是它有最大的壞處就是它顯然是比較weak 
因為沒有word level information 
就像我們剛才講的
你就只能把它看成是
不後面會接改
雖然沒什麼道理但是你就把它看成是這樣子
哦
這個腦後面接科你還以為是那個醫學院的腦科
等等
那麼做後面接方那不曉得為什麼不過反正有
你就是就是因為沒有word level 的沒有詞的level 的知識你只有字level 那你就用字level 去算
是可以但是你缺少一點東西
那所以它會比較weak 
那還有一個很大的問題就是說
你可能需要higher order 到相當程度才能夠代表
為什麼因為譬如說你你這個trigram 
是這兩個word 後面接這個word 
但是這是三字詞這是兩字詞這是三字詞
所以你如果要handle 這個relation 的話你要幾個一二三四五六七八要八gram 
你如果用字來做的話要八gram 才能夠做到這個relation 
啊
你如果只是bigram trigram 是不太夠的
你哦你這個relation 是用字來講是應該要用八gram 
那八gram 當然很難做了
所以你需要higher order n gram 
才能夠做到像詞這樣子的關係這trigram 
可是你要這麼n 如果這麼大的話是不容易做的
所以這個是用字來做的缺點
那用詞來做的話當然好處就是說詞就是真正的building block of sentence 
我們造個句子其實是用詞造的嘛啊
就像我們剛才講的
這個句子顯然你不是用一個字一個字去拼的你是用一個詞一個詞去拼的
不管你心目中的詞的哪一個
那你是用詞造出來的
所以呢你你你造個句字的時候事實上是是真正是用word 用詞來做所以是是比較好的
而且你可以加更多的information 
就以我們之前的所謂加更多的information 就以我們之前的例子來講
你就是可以把像它的詞類啦
什麼嗯
這些詞類的知識可以放進來這就是用詞做的好處用字就沒有了嘛
然後呢但是呢關鍵是說你有沒有一個好的詞典
你如果這個lexicon 如果不存在就沒有辦法了
那但是呢我們不太容易有一個很好的詞典
因為你不管做得多好的詞典總會漏掉一大堆詞
我們的這個oov rate 是非常高的
那麼你你不管你我的詞我們剛才講六萬詞你即使變成十六萬詞還是很多詞都沒有
二十六萬詞還是很多詞都沒有
你這是不太容易做
那當然還有一個問題就是你怎麼做斷詞
那麼我們剛才講一堆做斷詞的方法不表示這個就就很work 
因為斷詞永遠有有一堆錯誤嘛
所以
那通常我們的做法就是說
你斷詞不可能期待百分之一百正確
但是就是用一個軟體來做斷詞的好處就是讓它consistent 
如果它會把誰斷開來就它每一次都斷開就對了
譬如說科技的它一定會把的斷開來的話
你就的就會斷開來
你不能說有的時候的跟前面連在一起有的時候不連那這個就麻煩了
你就是要做consistent 的斷
不管它斷得對不對要consistent 
用一個程式來做有一個好處就是它會做得consistent 的話呢有它還有一定的效果就是了
所以會有嚴重的oov 的問題
sil
那到底怎麼做比較好那麼
有一段時間大家都不知道怎麼做比較好
不過後來我們想了一個非常好的辦法turns out 
這是一個簡單而有效的solution 
那麼這個solution 用了十多年前我們就已經知道
那麼一直到今天仍然是一個非常好的solution 
甚麼solution 呢就是我們講的你用詞來做
但是你把所有的字都當成單字詞也放進去
什麼意思
我有一個詞
六萬詞典六萬個
ok 
我就把這六萬個詞的詞典
那我還有一大堆的oov 怎麼辦
我就把所有的字
我有八千個常用字當成單字詞放進去
於是我就有六萬八千個
我這裡面所有的詞都有
常所有的常用詞都有
所有的單字詞都有
那這樣之後呢
我somehow 可以handle oov 的問題
為什麼
譬如說只要是一個常用的oov 
我可以解決
為什麼呢我們舉例來講譬如說呂秀蓮
這是一個oov 假設我沒有把她放在詞典裡面的話她是一個oov 
但是呢我現在假設我從網路裡面download 一大堆data 來開始要train language model 的時候
我就用這個詞典來斷詞
我用這個詞典來斷詞的時候呢這個詞典裡面沒有呂秀蓮
但是這三個字都是單字詞
所以我就會把它斷成三個單字詞
這三個單字詞
如果這個這三個單字詞連在一起的這個呂秀蓮這個這個詞在這個網路上面出現得夠多次的話
它的bigram trigram 
train 得夠強的話
它們自己就有就強了嘛
所以到時候我現在聽到一個呂
一個秀
一個蓮的時候
唉怎麼辦
我現在沒有一個雙字詞是呂秀沒有一個秀蓮的話嗯
那結果我就可能會把他變成這個是呂這是秀這是蓮
因為它們的trigram 
它們bigram trigram 夠強結果出來就是呂秀蓮
這個在在多少年以前的當時這個做出來的時候人家很不相信
你說這個字沒有在詞典裡面
可是為什麼我說這三個這三個音的時候它會知道呢
不可能嘛
是可能的就是這樣做的啊
這是這個
只是說這個只能只只限於就是在database 裡面頻率夠高的高頻詞的話如果它夠高頻
即使它是oov 也會對
啊那就是因為這些單字詞是都變成一個單這些字都變成單所有的字都變成單字詞放在詞典裡面
所以我斷詞的時候就把它們當成一堆非常高頻的trigram 跟bigram 的單字詞
所以呢我就辨識都會正確
但是呢這個限於高頻你如果頻率不夠高的話
這個n gram 不夠強是出不來的就是了
這是講這句話講的意思就是就是這一招
那當然你也可以想說我是可以把這個我是可以把這個嗯同時做詞的做字的跟做class 的
真都都全部可以整合在一起也是做得到的啦啊
那會比較好了不不過有夠複雜就是了
