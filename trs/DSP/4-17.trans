有了這個之後我們現在可以把它 extend 到我們先說 two  dimension
如果 two  dimension 的這個變成 vector  quantization 意思是什麼呢
我們舉例來講就是我把相鄰兩個當成一個 two  d 的 vector
譬如說這一個跟這一個
這兩個合成一個變成一個 two  d 的 vector
這兩個變成一個 two  d 的 vector
這兩個變成一個 two  d 的 vector 你可以這樣子來看
那如果是這樣子來的看的話呢我就變成一個 two  d 的 vector 是相鄰兩個 sample
那麼於是他們的 range 就這樣不是一個 dimension 了是兩個 dimension
於是呢就會變成
譬如說這樣變成這一塊
那譬如說這個軸是 x 的 n
那這個軸是 x 的 n 加一
那它變成一個 two  d 的兩兩 two  d 的一個 range
我的 s 變成這一塊它是在它都是在正負 a 之間
所以這個 x  n 呢也是在正負 a 之間從正 a 到負 a 
x  n 加一呢也是從正 a 到負 a 之間
在這裡面了
那這個時候我仍然可以做相同的事情
就是把這個 range 我也一樣的分成 l 塊
不過現在每一塊是 two  d 的 region
我還是寫成這個 j 　
因此呢我舉例來講呢你可能可以說呢
 ok 這裡有一塊
這裡有一塊
那麼這塊呢叫做 j  k
這中間你有一點呢叫做 v  k
還是一樣
那我這樣這塊 region 我總共可以分成譬如說 l 個
 l 個 two  d 的小塊
那我讓這些 l 個 two  d 小塊的聯集
仍然是整個的這個 s 這個就整個的 s 整個的 range
然後每一個 j  k 呢裡面有個代表值是小 v  k
那麼我的小 v  k 的集合呢叫做大 v
還是一樣
如果這樣的話我仍然是一個 two  d 是一個 mapping  relation
還是從這個 two  d 的 s 對應到這個 v 　
跟剛才是完全相同的
那麼這個 mapping 的方式也是一樣
如果你的 two  d 的那個 vector 掉在哪一塊我就對應到哪一個值
對不對
譬如說呢我的 x  one 是這個值
x  two 是這個值
於是掉到這一塊
在這一塊我就用這個代表了對不對
那這樣呢我這個如果我總共有我總共有 l 塊的話
是二的 r 次方
我仍然只要用 r 個 bit  pattern 就可以傳送了
就可以代表了
那這個是 v q 如果拿它來看成是這個傳送 data 的問題的話
我們可以這樣子看這個問題
那這個時候你可能會想到第一個問題就是說為什麼要這樣子做
這不是多此一舉嗎
因為我其實當你看成這樣的話
我馬上想到就是說那我其實就是把 x  one 的這個軸也切成幾塊
 x  two 這個軸也切成幾塊
不就一樣嗎
於是我就得到這樣子一堆正方形的或者長方形的
它們不一定要一樣長
就變成這樣就是啦這不就是那個嗎
沒有錯如果你這樣做的話
就跟剛才的 one  d 的這個是完全一樣的
對不對如果那樣做的話就跟這個是完全一樣
這個就沒有意義就這樣就好了
那麼會要這樣的原因就是
你可以想像這個並不是一個最好的辦法
因為它等於把你自己限成一堆框框
這堆框框把你完全限制成這樣子之後你這樣做的話就是原來那樣做法
但是其實我現在不一定要這樣子嘛我現在就可以變成別的樣子了
對不對我就變成別的樣子了
就不是那樣子那效果就會不同嘛
那麼為什麼會不同呢我們至少有這些個原因
一個最容易想像的原因就是它們這兩個之間是會有統計上的 correlation 的
所以它的 distribution 會不一樣
那麼最容易想的一個例子就是
如果這個 x  n 跟 x  n 加一是如剛才所說的這兩個相鄰的 sample 的話
如果是這兩個相鄰 sample 的話呢
in  most  case 它們值是比較接近的
你要說一個在這個上面一個在這個下面的機會是很少的
通常是都是蠻接近的
因此呢你就可以猜得到它的 distribution 是怎樣的
它大部分的 distribution 會集中在中間這一堆
那麼兩端是很少的
如果說它的 distribution 都在中間這一堆的話
那我其實我就可以把中間分得很細
就跟剛才的情形一樣
我中間可以分得很細
但這邊的情形是不太容易發生我就可以弄得很粗
這一大塊就好了這一大塊就好了因為它不太會發生
OK 那麼因此呢我就可以得到這個比較精緻的做法
那麼這樣子的話我就不再受限於這堆框框而
你可以想像這堆框框其實是多餘的
因為你搞到這邊來
這邊還是有一樣精細的框框跟這邊一樣
這個框跟這個框一樣是沒什麼道理因為它們本來就不一樣嘛
那麼你在這點的話是說一個這麼正一個這麼負其實不太可能嘛
哦等等所以你這邊就可以很鬆等等
那如果是這樣做的話呢
我們舉個例子來講
如果這邊是這個是這個
 r 是八個 bit  per  sample 的話
如果這裡的一個值是八個 bit  per  sample 所以 l 是兩百五十六格
我這邊分成兩百五十六格那麼每一個 sample 我用八個 bit 去描述它
我可以得到一個精細的代表
那麼當我變成兩個的時候
我如果仍然用這個框框來做的話呢
我就是要變成這個兩百五十六的平方 l 對不對
於是呢我其實還是就是十六個 bits  per  sample
這樣就跟剛才完全一樣
我這個這個軸也分成兩百五十六格八個 bit
這一軸也分成兩百五十六格八個 bit
這樣的話呢我兩個 bit 要十六個嗯十六個 bits  per 兩個 sample
對不對每兩個 sample 呢
是要十六個 bits
所以結果還是八個 bits  per  sample 是一樣的
但是你如果這樣做的話呢
我可以把這中間分得很細外面分得很粗
搞不好這樣我就只要譬如說兩千零四十八個 region 就夠了
我這邊不見得要分兩百五十六平方這麼多
我搞不好只要這樣就夠了如果這樣就夠的話呢
這個就是什麼這就是二的十一次方
於是呢我就只要十一個 bits  per 每兩個 sample
於是我一個 sample 呢只要五點五個 bit
比剛才的八個 bit 就省了很多等等
那你可以從這個觀點來想的話這個它就有它的意義
那這就是我們這邊講的這個
你為什麼要這樣子做
這樣做為什麼要這個把這些框框丟掉
而我重新去於這些奇奇怪怪的 region
那是有原因的
那原因就是我要做這類的事情
那我的考慮包括呢我的這個
這些東西可能是有這個這個統計上的 correlation 在
就像我剛剛講的這就是他的統統計上的 correlation 在
然後呢當然我可以有更 flexible 的 choice  of 每一塊可以更 flexible
那然後呢我的這個
還有一種可能就是 error  sensitivity 可能是 depends  on 它們 jointly
換句話說
如果我的一個 sample 非常準
一邊非常準的話
那另外一個搞不好我可以允許比較大的 error 可能沒什麼關係
譬如說你可以想像
如果其中一個已經很準了另外一個可能可以差很多都不影響等等
那這些的話就造成我可以做的空間
那麼因此呢這樣的話我就可以得到一個比較好的
那比較大的問題還是這倒底要怎麼做這件事
那這個如果做的好的話呢這每一個就是
每一個就是 j  k
那這裡面的每一個代表值就是 v  k
那麼這些 j  k 跟 v  k 的組合
就是所謂的我的 quantization 的 characteristics
或者說就是所謂的 code  book
就是嗯碼書啊它們有時候翻做碼書啊
就是 code  book
那就是那在哪裡歸在哪裡這樣的意思
那麼到這裡為止我們大概可以想像做 vector  quantization
這個嗯為什麼是一個 data  compression 的方法
原因我們剛才在最前面的這一頁說
它是一個 efficient  approach  for  data  compression
我可以把一組 real  number 變成一個 final  number  of  bits
所以我的 data 大為 compress
而且我 data 數目可以減少對不對
我現在這個兩個 sample 我只要十一個 bits
不像剛才要十六個 bits 譬如說
那這就是我的 data  compression 的功能
那當然這個觀念是可以衍生下去
那麼我們就可以得到更複雜的
舉例來講這個是 two  dimension 的
那當然你也可以 tree  dimension
然後可以變成 n  dimension
那這個情形都完全一樣這個 formulation 跟剛才都完全相同
那麼當你有這麼多 dimension 當然我們就沒有辦法畫了
我們也許最多只能畫一個 three  dimension 的
如果是 three  dimension 的話就變成一個像這樣
那它這塊就在這個裡面
然後那你中間還是一樣把它切成一塊一塊等等
three  d 的話大概就是這樣子啦
那你也是一樣你每一塊 three  d 的 region
我叫做 j  k
它有一個代表值叫做 v  k